{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "> By Jonas Busk ([jbusk@dtu.dk](mailto:jbusk@dtu.dk))\n",
    "\n",
    "**2019 update:** Changes have been made to the display of environments due to the previous `viewer` being incompatible with newer versions of Gym.\n",
    "\n",
    "**2022 update:** Rendering was disabled, and the notebook now uses the `colabgymrender` package to render a video.\n",
    "\n",
    "**2023 update:** Changed to packages `gymnasium` and `renderlab`, and to `CartPole-v1`.\n",
    "\n",
    "In this lab we will create neural network reinforcement learning agents with [PyTorch](https://pytorch.org/) to navigate various environments from [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) originally developed by [OpenAI](https://openai.com/).\n",
    "\n",
    "Please refer to the [docs](https://gymnasium.farama.org) on how to get started with Gymnasium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Below is a brief guide on how to install Gymnasium. For more details, please refer to the repository on [GitHub](https://gymnasium.farama.org) and the [docs](https://gym.openai.com/docs).\n",
    "\n",
    "You can do a minimal install of the packaged version of Gym directly from PyPI:\n",
    "\n",
    "```\n",
    "pip install gymnasium\n",
    "```\n",
    "\n",
    "If you run in Colab, you can do a quick pip install of Gym in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium) (2.1.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: renderlab in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (0.1.20230421184216)\n",
      "Requirement already satisfied: moviepy in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from renderlab) (1.0.3)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from renderlab) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium->renderlab) (2.1.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium->renderlab) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium->renderlab) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium->renderlab) (0.0.4)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (2.36.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from moviepy->renderlab) (0.5.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy->renderlab) (11.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy->renderlab) (70.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy->renderlab) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install renderlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **If run on your local machine**, you may need to install `gymnasium[classic-control]` by running the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium[classic-control]) (2.1.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium[classic-control]) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium[classic-control]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\musti\\onedrive - danmarks tekniske universitet\\masters\\deep learning\\02456-deep-learning-with-pytorch\\.venv\\lib\\site-packages (from gymnasium[classic-control]) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"gymnasium[classic-control]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an environment\n",
    "\n",
    "Here is a bare minimum example of running a Gym environment. This creates an instance of the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) environment and runs until the rollout is done, taking random actions and rendering the environment at each step. With Gym installed, you should be able to see a small animation of the environment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video temp-{start}.mp4.\n",
      "Moviepy - Writing video temp-{start}.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready temp-{start}.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import renderlab as rl\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\") # Create the environment\n",
    "env = rl.RenderFrame(env, \"./output\") # Directory for the recorded video\n",
    "env.reset()\n",
    "\n",
    "# Run environment\n",
    "while True:\n",
    "    action = env.action_space.sample() # Get a random action\n",
    "    _, _, done, _, _ = env.step(action) # Take a step\n",
    "\n",
    "    \n",
    "    if done: break # Break if environment is done\n",
    "\n",
    "env.close() # Close environment\n",
    "env.play() # Show the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! You now have a working `Gym` environment that we can take actions in and render."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
